from call_LLaVA import call_LLaVA_with_attention
import os
import numpy as np
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from aokvqa.load_aokvqa import load_aokvqa, get_coco_path
from llava.model.builder import load_pretrained_model
from llava.utils import disable_torch_init
from llava.mm_utils import get_model_name_from_path

# **1. é¢„åŠ è½½ LLaVA æ¨¡å‹**
disable_torch_init()
model_path = "liuhaotian/llava-v1.5-7b" # aria, long va
model_name = get_model_name_from_path(model_path)

print("ğŸ”„ Loading LLaVA model, please wait...")
tokenizer, model, image_processor, context_len = load_pretrained_model(
    model_path, None, model_name, attn_implementation="eager"
)
model.config.output_attentions = True
model.eval()  # è¿›å…¥æ¨ç†æ¨¡å¼ï¼Œå‡å°‘è®¡ç®—
print("Model loaded successfully!")

# è®¾ç½®æ•°æ®é›†è·¯å¾„
aokvqa_dir = "./aokvqa/datasets/aokvqa/"
coco_dir = "./aokvqa/datasets/coco/"
train_dataset = load_aokvqa(aokvqa_dir, 'train')

# ä»…å¤„ç†å‰ 50 ä¸ªæ ·æœ¬
num_samples = min(50, len(train_dataset))

# åˆ›å»ºä¿å­˜ç›®å½•
output_dir = "attention_analysis"
os.makedirs(output_dir, exist_ok=True)

# å¤„ç†æ•°æ®å¹¶æ·»åŠ è¿›åº¦æ¡
attention_results = {}
for i in tqdm(range(num_samples), desc="Processing dataset", unit="sample"):
    dataset_example = train_dataset[i]

    # è·å–é—®é¢˜å’Œå›¾åƒè·¯å¾„
    question_id = dataset_example['question_id']
    question = dataset_example['question']
    choices = dataset_example['choices']
    correct_choice = choices[dataset_example['correct_choice_idx']]
    image_path = get_coco_path('train', dataset_example['image_id'], coco_dir)

    # è°ƒç”¨ LLaVAï¼Œä½†ä¸é‡å¤åŠ è½½æ¨¡å‹
    result, attn_weights, split_index = call_LLaVA_with_attention(
        question, image_path, tokenizer, model, image_processor
    )
    
    # ä¿å­˜æ³¨æ„åŠ›æ•°æ®ï¼ŒåŒæ—¶è®°å½• split_index
    attention_results[question_id] = {
        "question": question,
        "choices": choices,
        "correct_choice": correct_choice,
        "generated_text": result,
        "attention": attn_weights,
        "split_index": split_index  # è®°å½• split_index
    }

    # æ‰“å°è°ƒè¯•ä¿¡æ¯
    print(f"Processed {i+1}/{num_samples} - QID: {question_id}, Correct: {correct_choice}, Split Index: {split_index}")

# ä¿å­˜æ‰€æœ‰æ³¨æ„åŠ›æƒé‡ï¼ˆåŒ…æ‹¬ split_indexï¼‰
np.savez_compressed(os.path.join(output_dir, "attention_data.npz"), **attention_results)

print("Processing complete! Data saved.")
