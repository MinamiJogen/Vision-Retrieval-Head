=========================================
å¼€å§‹æµ‹è¯• Qwen2.5-VL-7B-Instruct - Thu 04 Sep 2025 03:45:05 AM +08
å®Œæ•´æ—¥å¿—å°†ä¿å­˜åˆ°: ./testlogs/qwen25_vl_7b_20250904_034505.log
=========================================

>>> æ¨¡å‹è·¯å¾„: Qwen/Qwen2.5-VL-7B-Instruct
>>> å¼€å§‹è¯„æµ‹ VideoMME...
>>> å¼€å§‹æ—¶é—´: Thu 04 Sep 2025 03:45:05 AM +08
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2025-09-04 03:45:13.925[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m295[0m - [1mVerbosity set to INFO[0m
[32m2025-09-04 03:45:15.660[0m | [33m[1mWARNING [0m | [36mlmms_eval.tasks[0m:[36m_get_task_and_group[0m:[36m473[0m - [33m[1mThe tag coco_karpathy is already registered as a group, this tag will not be registered. This may affect tasks you want to call.[0m
[32m2025-09-04 03:45:16.217[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m378[0m - [1mEvaluation tracker args: {'output_path': './testlogs/qwen25_vl_7b_videomme.json'}[0m
[32m2025-09-04 03:45:16.217[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m467[0m - [1mSelected Tasks: ['videomme'][0m
[32m2025-09-04 03:45:16.219[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
Fetching 24 files:   0%|          | 0/24 [00:00<?, ?it/s]Fetching 24 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 8439.95it/s]
`torch_dtype` is deprecated! Use `dtype` instead!
You are using a model of type qwen2_5_vl to instantiate a model of type qwen2_vl. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/disk3/minami/Vision-Retrieval-Head/lmms-eval/lmms_eval/__main__.py", line 330, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/disk3/minami/Vision-Retrieval-Head/lmms-eval/lmms_eval/__main__.py", line 471, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/disk3/minami/Vision-Retrieval-Head/lmms-eval/lmms_eval/utils.py", line 533, in _wrapper
    return fn(*args, **kwargs)
  File "/disk3/minami/Vision-Retrieval-Head/lmms-eval/lmms_eval/evaluator.py", line 176, in simple_evaluate
    lm = lmms_eval.models.get_model(model).create_from_arg_string(
  File "/disk3/minami/Vision-Retrieval-Head/lmms-eval/lmms_eval/api/model.py", line 110, in create_from_arg_string
    return cls(**args, **args2)
  File "/disk3/minami/Vision-Retrieval-Head/lmms-eval/lmms_eval/models/qwen2_vl.py", line 74, in __init__
    self._model = Qwen2VLForConditionalGeneration.from_pretrained(pretrained, torch_dtype="auto", device_map=self.device_map).eval()
  File "/home/minami/miniconda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 288, in _wrapper
    return func(*args, **kwargs)
  File "/home/minami/miniconda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5176, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/minami/miniconda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5639, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
  File "/home/minami/miniconda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 946, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
  File "/home/minami/miniconda/envs/qwen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/minami/miniconda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 850, in _load_state_dict_into_meta_model
    _load_parameter_into_model(model, param_name, param.to(param_device))
  File "/home/minami/miniconda/envs/qwen/lib/python3.10/site-packages/transformers/modeling_utils.py", line 710, in _load_parameter_into_model
    module.load_state_dict({param_type: tensor}, strict=False, assign=True)
  File "/home/minami/miniconda/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for Linear:
	size mismatch for bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([1280]).
[32m2025-09-04 03:45:34.442[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m349[0m - [31m[1mError during evaluation: Error(s) in loading state_dict for Linear:
	size mismatch for bias: copying a param with shape torch.Size([3584]) from checkpoint, the shape in current model is torch.Size([1280]).. Please set `--verbosity=DEBUG` to get more information.[0m
>>> è¯„æµ‹æˆåŠŸ
>>> ç»“æœä¿å­˜åˆ°: ./testlogs/qwen25_vl_7b_videomme.json

=========================================
è¯„æµ‹å®Œæˆ - Thu 04 Sep 2025 03:45:36 AM +08
ç»“æœæ–‡ä»¶: ./testlogs/qwen25_vl_7b_videomme.json
å®Œæ•´æ—¥å¿—: ./testlogs/qwen25_vl_7b_20250904_034505.log
=========================================

æ—¥å¿—æ–‡ä»¶ä¿¡æ¯ï¼š
-rw-rw-r-- 1 minami minami  14K Sep  4 03:03 ./testlogs/qwen25_vl_7b_20250904_030349.log
-rw-rw-r-- 1 minami minami 8.0K Sep  4 03:07 ./testlogs/qwen25_vl_7b_20250904_030423.log
-rw-rw-r-- 1 minami minami 4.8K Sep  4 03:09 ./testlogs/qwen25_vl_7b_20250904_030923.log
-rw-rw-r-- 1 minami minami 1.8K Sep  4 03:20 ./testlogs/qwen25_vl_7b_20250904_032018.log
-rw-rw-r-- 1 minami minami 5.6K Sep  4 03:45 ./testlogs/qwen25_vl_7b_20250904_034505.log
